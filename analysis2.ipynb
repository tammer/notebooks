{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = 'data/qa_queries_V28.parquet'\n",
    "#load data\n",
    "df = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by lat, time\n",
    "df = df.sort_values(by=['lat', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['point', 'time', 'lat', 'lon', 'ndvi.landsat', 'qa.landsat',\n",
       "       'ndvi.modis', 'qa.modis', 'ndvi.sentinel2', 'qa.sentinel2',\n",
       "       'ndvi.streambatch', 'source.streambatch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>-34.065146</td>\n",
       "      <td>0.451291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-20</td>\n",
       "      <td>-34.065146</td>\n",
       "      <td>0.718348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-08-05</td>\n",
       "      <td>-34.065146</td>\n",
       "      <td>0.688542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-08-12</td>\n",
       "      <td>-34.065146</td>\n",
       "      <td>0.763199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-09-06</td>\n",
       "      <td>-34.065146</td>\n",
       "      <td>0.680351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time        lat      ndvi\n",
       "0 2013-04-22 -34.065146  0.451291\n",
       "1 2013-07-20 -34.065146  0.718348\n",
       "2 2013-08-05 -34.065146  0.688542\n",
       "3 2013-08-12 -34.065146  0.763199\n",
       "4 2013-09-06 -34.065146  0.680351"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice off all rows where qa.sentinel2 == 1\n",
    "s2 = df[df['qa.sentinel2'] == 1].copy()\n",
    "\n",
    "# remove all columns except time, lat, ndvi.sentinel2\n",
    "s2 = s2[['time', 'lat', 'ndvi.sentinel2']]\n",
    "# rename ndvi.sentinel2 to ndvi\n",
    "s2 = s2.rename(columns={'ndvi.sentinel2': 'ndvi'})\n",
    "# remove any row where ndvi is the same as the previous row\n",
    "s2 = s2[s2['ndvi'] != s2['ndvi'].shift(1)]\n",
    "\n",
    "# slice off all rows where qa.landsat8 == 1\n",
    "l8 = df[df['qa.landsat'] == 1].copy()\n",
    "# remove all columns except time, lat, ndvi.landsat\n",
    "l8 = l8[['time', 'lat', 'ndvi.landsat']]\n",
    "# rename ndvi.landsat to ndvi\n",
    "l8 = l8.rename(columns={'ndvi.landsat': 'ndvi'})\n",
    "# remove any row where ndvi is the same as the previous row\n",
    "l8 = l8[l8['ndvi'] != l8['ndvi'].shift(1)]\n",
    "# concat s2 and l8\n",
    "m = pd.concat([s2, l8])\n",
    "# sort by lat, time\n",
    "m = m.sort_values(by=['lat', 'time'])\n",
    "# reset index\n",
    "m = m.reset_index(drop=True)\n",
    "m.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the unique lats\n",
    "lats = df['lat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "\n",
    "def f(m):\n",
    "\n",
    "    # Step 2: Create a new DataFrame 'm1' with all dates from the minimum to maximum date in 'm'\n",
    "    min_date = m[\"time\"].min()\n",
    "    max_date = m[\"time\"].max()\n",
    "    date_range = pd.date_range(min_date, max_date, freq='D')  # Create a date range with daily frequency\n",
    "    m1 = pd.DataFrame({\"time\": date_range})\n",
    "\n",
    "    # Step 3: Merge the original 'ndvi' values into the new DataFrame 'm1' using outer join\n",
    "    m1 = pd.merge(m1, m, on=\"time\", how=\"left\")\n",
    "\n",
    "    # Step 2: Define Kalman filter model parameters\n",
    "    # We assume a simple constant velocity model for this example\n",
    "    transition_matrix = [[1, 1], [0, 1]]  # State transition matrix\n",
    "    observation_matrix = np.array([[1, 0]])  # Observation matrix\n",
    "    initial_state_mean = [m1[\"ndvi\"].dropna().iloc[0], 0]  # Initial state [initial value, initial velocity]\n",
    "    initial_state_covariance = np.eye(2)  # Initial covariance matrix\n",
    "    observation_covariance = np.eye(1)  # Observation covariance matrix\n",
    "    transition_covariance = np.eye(2)  # State transition covariance matrix\n",
    "\n",
    "    # Step 3: Implement Kalman filter algorithm to estimate missing values\n",
    "    # Initialize the Kalman filter with the model parameters\n",
    "    kf = KalmanFilter(\n",
    "        transition_matrices=transition_matrix,\n",
    "        observation_matrices=observation_matrix,\n",
    "        initial_state_mean=initial_state_mean,\n",
    "        initial_state_covariance=initial_state_covariance,\n",
    "        observation_covariance=observation_covariance,\n",
    "        transition_covariance=transition_covariance\n",
    "    )\n",
    "\n",
    "    # Store observed \"ndvi\" values (without NaNs) in an array\n",
    "    observed_ndvi = m1[\"ndvi\"].dropna().values.reshape(-1, 1)\n",
    "\n",
    "    # Use the Kalman filter to estimate the missing values (NaNs)\n",
    "    (filtered_state_means, _) = kf.filter(observed_ndvi)\n",
    "\n",
    "    # Create a new DataFrame with the estimated \"ndvi\" values\n",
    "    m1_estimated = m1.copy()\n",
    "    m1_estimated.loc[m1[\"ndvi\"].isnull(), \"ndvi\"] = filtered_state_means[-m1[\"ndvi\"].isnull().sum():]\n",
    "\n",
    "\n",
    "\n",
    "    return m1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m m1 \u001b[39m=\u001b[39m m[m[\u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m lats[\u001b[39m0\u001b[39m]]\n\u001b[1;32m      4\u001b[0m m1 \u001b[39m=\u001b[39m m1[(m1[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m start_date) \u001b[39m&\u001b[39m (m1[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m end_date)]\n\u001b[0;32m----> 5\u001b[0m fitted \u001b[39m=\u001b[39m f(m1)\n\u001b[1;32m      6\u001b[0m \u001b[39m# fitted['ndvi_'] = fitted['ndvi'].interpolate(method='linear', limit_direction='both')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m fitted\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[10], line 46\u001b[0m, in \u001b[0;36mf\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m# Create a new DataFrame with the estimated \"ndvi\" values\u001b[39;00m\n\u001b[1;32m     45\u001b[0m m1_estimated \u001b[39m=\u001b[39m m1\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 46\u001b[0m m1_estimated\u001b[39m.\u001b[39;49mloc[m1[\u001b[39m\"\u001b[39;49m\u001b[39mndvi\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49misnull(), \u001b[39m\"\u001b[39;49m\u001b[39mndvi\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m filtered_state_means[\u001b[39m-\u001b[39mm1[\u001b[39m\"\u001b[39m\u001b[39mndvi\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum():]\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m m1\n",
      "File \u001b[0;32m~/dev/streambatch/myenv2/lib/python3.9/site-packages/pandas/core/indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    848\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[0;32m--> 849\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/dev/streambatch/myenv2/lib/python3.9/site-packages/pandas/core/indexing.py:1828\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1827\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1828\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[1;32m   1829\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1830\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/dev/streambatch/myenv2/lib/python3.9/site-packages/pandas/core/indexing.py:1868\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1863\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[1;32m   1865\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mndim(value) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1866\u001b[0m     \u001b[39m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m     \u001b[39m#  that will construct an ndarray, which will be wasteful\u001b[39;00m\n\u001b[0;32m-> 1868\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_2d_value(indexer, value)\n\u001b[1;32m   1870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(ilocs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m lplane_indexer \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(value) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(pi):\n\u001b[1;32m   1871\u001b[0m     \u001b[39m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(ilocs[\u001b[39m0\u001b[39m], value, pi)\n",
      "File \u001b[0;32m~/dev/streambatch/myenv2/lib/python3.9/site-packages/pandas/core/indexing.py:1934\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1932\u001b[0m     value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(value, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[1;32m   1933\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ilocs) \u001b[39m!=\u001b[39m value\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m-> 1934\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1935\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1936\u001b[0m     )\n\u001b[1;32m   1938\u001b[0m \u001b[39mfor\u001b[39;00m i, loc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ilocs):\n\u001b[1;32m   1939\u001b[0m     value_col \u001b[39m=\u001b[39m value[:, i]\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2022-12-31'\n",
    "m1 = m[m['lat'] == lats[0]]\n",
    "m1 = m1[(m1['time'] >= start_date) & (m1['time'] <= end_date)]\n",
    "fitted = f(m1)\n",
    "# fitted['ndvi_'] = fitted['ndvi'].interpolate(method='linear', limit_direction='both')\n",
    "fitted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2022-12-31'\n",
    "for l in lats:\n",
    "    this = df[df['lat'] == l]\n",
    "    m1 = m[m['lat'] == l]\n",
    "    this = this[(this['time'] >= start_date) & (this['time'] <= end_date)]\n",
    "    m1 = m1[(m1['time'] >= start_date) & (m1['time'] <= end_date)]\n",
    "\n",
    "    \n",
    "    fitted = f(m1)\n",
    "\n",
    "\n",
    "    # plot ndvi.streambatch vs time\n",
    "    plt.scatter(this['time'], this['ndvi.streambatch'], label='streambatch',s=5,color='orange')\n",
    "    plt.scatter(fitted['time'], fitted['ndvi_smoothed'], label='savgol',s=5,color='blue')\n",
    "    plt.scatter(m1['time'], m1['ndvi'], label='sentinel and landsat',s=14, color=\"red\")\n",
    "    plt.title(f\"lat: {l} plot 1: Streambatch plot2: savgol applied to just s2 and landsat\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    # plt.scatter(m1['time'], m1['ndvi'], label='sentinel and landsat',s=10, color=\"red\")\n",
    "    # plt.scatter(fitted['time'], fitted['ndvi_smoothed'], label='savgol',s=5, color='blue')\n",
    "    # plt.title(f\"lat: {l} same location as above. Sentinel2/Landsat and savgol applied to it\")\n",
    "    # plt.legend()\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    plt.scatter(fitted['time'], fitted['ndvi_smoothed'], label='savgol',s=5, color='blue')\n",
    "    plt.title(f\"lat: {l} Just Savgol\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
