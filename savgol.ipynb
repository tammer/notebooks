{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Find outliers\n",
    "# ndvi(t) is an outlier if:\n",
    "# 1) abs(zscore) > 1.5 (relative to it's two neighbours on each side)\n",
    "# 2) it is \"far\" away from the mean in absolute terms too, i.e.\n",
    "#    ndvi(t) - mean > 0.2\n",
    "#\n",
    "def find_outliers(m2):\n",
    "    # compure zscore for every point using two points before and two points after each point\n",
    "    window_size = 7\n",
    "    rolling_mean = m2['ndvi'].rolling(window=window_size, center=True).mean()\n",
    "    rolling_std = m2['ndvi'].rolling(window=window_size, center=True).std()\n",
    "\n",
    "    # Calculate the z-score for each point\n",
    "    m2['rolling mean'] = rolling_mean\n",
    "    m2['rolling std'] = rolling_std\n",
    "    m2['zscore'] = (m2['ndvi'] - rolling_mean) / rolling_std\n",
    "    m2['delta'] = m2['ndvi'] - m2['rolling mean']\n",
    "    m2['outlier'] = (m2['delta'].abs() > 0.2) & (m2['zscore'].abs() > 1.5)\n",
    "    return m2\n",
    "\n",
    "# m is a dataframe with columns time and ndvi\n",
    "def remove_outliers(m):\n",
    "    m1 = m.copy()\n",
    "    m1 = find_outliers(m1)\n",
    "    m2 = m1[m1['outlier']==False]\n",
    "    # print(f\"removed {m1.shape[0] - m2.shape[0]} outliers\")\n",
    "    y = pd.DataFrame()\n",
    "    y['time'] = m2['time'].values\n",
    "    y['ndvi'] = m2['ndvi'].values\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ is a dataframe where column 0 is time and column 1 is ndvi other colums are ignored\n",
    "def savgol(df_,window_length=20,polyorder=2):\n",
    "    # rename the first column as 'time' and the second as 'ndvi'\n",
    "    m = pd.DataFrame()    \n",
    "    m['time'] = df_.iloc[:,0]\n",
    "    m['ndvi'] = df_.iloc[:,1]\n",
    "    m = remove_outliers(m)\n",
    "    min_date = m[\"time\"].min()\n",
    "    max_date = m[\"time\"].max()\n",
    "    date_range = pd.date_range(min_date, max_date, freq='D')\n",
    "    m1 = pd.DataFrame({\"time\": date_range})\n",
    "\n",
    "    # Merge the original 'ndvi' values into the new DataFrame 'm1' using outer join\n",
    "    m1 = pd.merge(m1, m, on=\"time\", how=\"left\")\n",
    "\n",
    "    # Interpolate missing values in the 'ndvi' column\n",
    "    m1[\"ndvi\"] = m1[\"ndvi\"].interpolate()\n",
    "\n",
    "    # Fill missing values with NaN, so the filter doesn't treat them as zeros\n",
    "    m1[\"ndvi\"] = m1[\"ndvi\"].replace(0, np.nan)\n",
    "\n",
    "    # Apply the savgol_filter to smooth the \"ndvi\" column\n",
    "    m1[\"ndvi_smoothed\"] = savgol_filter(m1[\"ndvi\"], window_length, polyorder)\n",
    "\n",
    "    # usefull for comparing savvol with original inputs\n",
    "    # l = []\n",
    "    # for t in m['time'].values:\n",
    "    #     ndvi_value = m1[m1['time']==t]['ndvi_smoothed'].values[0]\n",
    "    #     l.append(ndvi_value)\n",
    "    # m['savgol point'] = l\n",
    "    # return m1,m\n",
    "\n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ndvi_data():\n",
    "    file_name = 'data/qa_queries_V28.parquet'\n",
    "    df = pd.read_parquet(file_name)\n",
    "    df = df.sort_values(by=['lat', 'time'])\n",
    "    # slice off all rows where qa.sentinel2 == 1\n",
    "    s2 = df[df['qa.sentinel2'] == 1].copy()\n",
    "    # remove all columns except time, lat, ndvi.sentinel2\n",
    "    s2 = s2[['time', 'lat', 'ndvi.sentinel2']]\n",
    "    # rename ndvi.sentinel2 to ndvi\n",
    "    s2 = s2.rename(columns={'ndvi.sentinel2': 'ndvi'})\n",
    "    # remove any row where ndvi is the same as the previous row\n",
    "    s2 = s2[s2['ndvi'] != s2['ndvi'].shift(1)]\n",
    "\n",
    "    # slice off all rows where qa.landsat8 == 1\n",
    "    l8 = df[df['qa.landsat'] == 1].copy()\n",
    "    # remove all columns except time, lat, ndvi.landsat\n",
    "    l8 = l8[['time', 'lat', 'ndvi.landsat']]\n",
    "    # rename ndvi.landsat to ndvi\n",
    "    l8 = l8.rename(columns={'ndvi.landsat': 'ndvi'})\n",
    "    # remove any row where ndvi is the same as the previous row\n",
    "    l8 = l8[l8['ndvi'] != l8['ndvi'].shift(1)]\n",
    "    # concat s2 and l8\n",
    "    m = pd.concat([s2, l8])\n",
    "    # sort by lat, time\n",
    "    m = m.sort_values(by=['lat', 'time'])\n",
    "    # reset index\n",
    "    m = m.reset_index(drop=True)\n",
    "\n",
    "    # now lets get ndvi.streambatch\n",
    "    # slice off all rows where ndvi.streambatch is not nan\n",
    "    sb = df[df['ndvi.streambatch'].notnull()]\n",
    "    # remove all columns except time, lat, ndvi.streambatch\n",
    "    sb = sb[['time', 'lat', 'ndvi.streambatch']]\n",
    "    # sort by lat, time\n",
    "    sb = sb.sort_values(by=['lat', 'time'])\n",
    "    # reset index\n",
    "    sb = sb.reset_index(drop=True)\n",
    "    return m, sb\n",
    "\n",
    "raw_ndvi, streambatch_ndvi = load_ndvi_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(fitted_ndvi,streambatch_ndvi,title):\n",
    "    print(title)\n",
    "    plt.scatter(fitted_ndvi['time'], fitted_ndvi['ndvi_smoothed'], label='savgol',s=5,color='blue')\n",
    "    plt.scatter(streambatch_ndvi['time'], streambatch_ndvi['ndvi.streambatch'], label='ndvi.streambatch',s=5, color=\"red\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 1 outliers\n",
      "removed 1 outliers\n",
      "removed 5 outliers\n",
      "removed 6 outliers\n",
      "removed 10 outliers\n",
      "removed 8 outliers\n",
      "removed 5 outliers\n",
      "removed 4 outliers\n",
      "removed 3 outliers\n",
      "removed 11 outliers\n",
      "removed 5 outliers\n",
      "removed 8 outliers\n",
      "removed 3 outliers\n",
      "removed 2 outliers\n",
      "removed 1 outliers\n",
      "removed 3 outliers\n",
      "removed 5 outliers\n",
      "removed 5 outliers\n",
      "removed 5 outliers\n",
      "removed 7 outliers\n",
      "removed 2 outliers\n",
      "removed 18 outliers\n"
     ]
    }
   ],
   "source": [
    "lats = raw_ndvi['lat'].unique()\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for lat in lats:\n",
    "    ndvi_at_this_lat = raw_ndvi[raw_ndvi.lat==lat]\n",
    "    ndvi_at_this_lat = ndvi_at_this_lat[['time','ndvi']] # ditch the lat column\n",
    "    fitted = savgol(ndvi_at_this_lat,window_length=20,polyorder=2)\n",
    "    streambatch_ndvi_at_this_lat = streambatch_ndvi[streambatch_ndvi.lat==lat]\n",
    "    streambatch_ndvi_at_this_lat = streambatch_ndvi_at_this_lat[['time','ndvi.streambatch']] # ditch the lat column\n",
    "    for year in range(2015,2023):\n",
    "        start_date = f'{year}-01-01'\n",
    "        end_date = f'{year}-12-31'   \n",
    "        fitted_time_slice = fitted[(fitted.time >= start_date) & (fitted.time <= end_date)]\n",
    "        streambatch_time_slice = streambatch_ndvi_at_this_lat[(streambatch_ndvi_at_this_lat.time >= start_date) & (streambatch_ndvi_at_this_lat.time <= end_date)]\n",
    "        title = f'lat={lat}, year={year}'\n",
    "        # plot(fitted_time_slice, streambatch_time_slice,title)\n",
    "    fitted['lat'] = lat\n",
    "    all_data = pd.concat([all_data,fitted])\n",
    "\n",
    "all_data = all_data.reindex(columns=['lat', 'time', 'ndvi', 'ndvi_smoothed'])\n",
    "\n",
    "# if number of unique lats not equal to 22, then print error else save\n",
    "if len(all_data['lat'].unique()) != 22:\n",
    "    print('ERROR: Number of unique lats not equal to 22')\n",
    "else:\n",
    "    all_data.to_parquet('data/savgol.parquet')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
